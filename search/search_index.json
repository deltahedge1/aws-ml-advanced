{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AWS Machine Learning with Udacity","text":"<p>This is my site to write down notes from udacity course on advance machine learning with AWS</p>"},{"location":"#course-useful-links","title":"Course Useful links","text":"<ul> <li>Community site</li> <li>Timeline</li> <li>Course</li> </ul> <p>Note that all images and material are attributed from the udacity course machine learning fundimentals</p>"},{"location":"algorithms-tools/","title":"Algorithms And Tools","text":""},{"location":"algorithms-tools/#autogluon","title":"AutoGluon","text":"<p>AutoGluon is a framework that automates the processing, creating and tuning of ML models.</p> <p>Main parameters are 1. target value 2. how long to train for</p> <p>automates everything else</p> <pre><code>import pandas as pd\nfrom autogluon.tabular import TabularPredictor\n\ndf = pd.DataFrame(\n    [[1, 2, 0], [3, 4, 1], [5, 6, 0], [7, 8, 1]],\n    columns=[\"num\", \"amount\", \"target\"]\n)\n\npredictor = TabularPredictor(label=\"target\").fit(\n    train_data=df,\n    time_limit=60,\n    presets=\"best_quality\"\n)\n\n# output a summary of created models\npredictor.fit_summary()\n\n# evaluation best model from hyperparameter search\nperformance = predictor.evaluate(df)\n\n# leaderboard   \npredictor.leaderboard(silent=True).plot(kind=\"bar\", x=\"model\", y=\"score_val\")\n</code></pre> <pre><code>predictor.transform_features(test_data)\npredictor.feature_importance(test_data)\npredictor.model_best\n</code></pre> <pre><code>from autogluon.common import space #check this form hyperparameter tuning\n</code></pre> <ul> <li> <p>AutoGluon documentation</p> </li> <li> <p>AutoGluon Wiki page</p> </li> <li> <p>awesome-AutoML</p> </li> </ul>"},{"location":"creating-budget-alerts/","title":"How to Create Budget Alerts","text":"<ol> <li> <p>create a new role</p> <ul> <li>Open Roles.       </li> <li>Click Create role button.     </li> <li>Choose AWS account.       </li> <li>Click next.       </li> <li>Attach <code>AWSBudgetsActionsWithAWSResourceControlAccess</code> Policy to it.      </li> <li>CLick next.       </li> <li>Type a name for that role.        </li> <li>Click create role.</li> </ul> </li> <li> <p>Switch to that role.     </p> <ul> <li>Search for the role in the roles console.     </li> <li>Click on the role link.       </li> <li>Copy the Link to switch roles in the console.     </li> <li>Paste the link in the browser URL window and Enter to switch to that role.</li> </ul> </li> <li> <p>Budget Setup:        </p> <ul> <li>Search for Budgets in the AWS Console and open it.        </li> <li>Click Create Budget       </li> <li>Customize (Advance) &gt; Cost budget - Recommended       </li> <li>Click Next        </li> <li>Type the Budget name.     </li> <li>Select the Period to be Daily.        </li> <li>Enter your budgeted Amount ($): type 0.5 (half a dollar).     </li> <li>Click Next        </li> <li>Click Add an alert threshold.     </li> <li>Set the Threshold by typing 100 in the Threshold box.     </li> <li>Type your email in the Email recepients box.      </li> <li>Click Next, then Create budget to finish and create the budget.       </li> <li>Sign out of the account and repeat the process for Course 4 account.</li> </ul> </li> </ol>"},{"location":"deeplearning/","title":"Deep Learning","text":""},{"location":"deeplearning/#preview","title":"Preview","text":"<ul> <li>How experts think about Deep Learning. This gives us a framework to understand when we should use Deep Learning.</li> <li>The differences between Artificial Intelligence, Machine Learning, and Deep Learning.</li> <li>The origins and history of Deep Learning.</li> <li>Tools for using Deep Learning.</li> <li>Applications of Deep Learning.</li> </ul>"},{"location":"deeplearning/#books-to-read","title":"Books to Read","text":"<p>Grokking Deep Learning by Andrew Trask. Use our exclusive discount code traskud17 for 40% off. This provides a very gentle introduction to Deep Learning and covers the intuition more than the theory.</p> <p>Neural Networks And Deep Learning by Michael Nielsen. This book is more rigorous than Grokking Deep Learning and includes a lot of fun, interactive visualizations to play with.</p> <p>Inside Deep Learning by Edward Raff is an excellent intermediate book that covers much of the mathematical background, in-depth looks at modern neural network architectures, and develops a good intuition.</p> <p>The Deep Learning Textbook from Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Often simply called \"the Deep Learning book\", it is a rigorous treatment of the mathematics and theory behind deep learning, in addition to covering a number of important practical issues.</p> <p>Deep Learning Architectures by Ovidiu Calin is by far the most theoretical book on this list, and the most challenging in terms of mathematical prerequisites. However, if you want to conduct groundbreaking research in neural networks, this book is an excellent reference to have on hand.</p>"},{"location":"deeplearning/#deep-learning-thoughts-from-experts","title":"Deep learning thoughts from experts","text":"<p>Deep learning is the path to everything, to artifical general intelligence (singularity)</p> <p>Empherical results of deep learning are unparrellel</p> <p>People think of one tool in the toolbox, however there are many tools</p> <p>Draw backs 1. lack of causaility 2. lack of explainability 3. having to check the results</p>"},{"location":"deeplearning/#ai-ml-deep-learning","title":"AI, ML, &amp; Deep Learning","text":"<p>Deep learning is a subfield of AI and ML</p> <p>As we can see, Artificial Intelligence is the overarching field and includes algorithms like Local Search and Logic Programming. Machine Learning is a part of Artificial Intelligence and includes models like Logistic Regression and Decision Trees. Deep Learning is a subfield of Machine Learning that consists of various neural network models.</p>"},{"location":"deeplearning/#dl-life-cycle","title":"DL life cycle","text":""},{"location":"deeplearning/#tools-for-deep-learning","title":"Tools For Deep Learning","text":"<p>Development tools     - Integrated Development Environment     - Code Editor     - Interpreter/Compiler     - Jupyter Notebooks     - Note: Each cell is executed on its own, and it works well for environments to prototype or present code. However, there are limitations:         - Editing can make you lose state         - Code deployed production should be in .py rather than notebooks</p> <p>Deep Learning Frameworks     - PyTorch (aka Torch)     - TensorFlow/Keras     - JAX (Develop by google similar to numpy)</p> <p>Training Tools     - Experiment management like <code>TensorBoard</code> or <code>Weights and Biases</code>         - Observe accuracy and loss at training time     - Model versioning like <code>DVC</code>, <code>Neptune</code>, and <code>Pachyderm</code>         - Remedy issues within the model across different versions of the model         - DVC is very similar to Git</p>"},{"location":"deeplearning/#pytorch-basics","title":"Pytorch Basics","text":"<pre><code>import torch\nimport numpy as np\n\ndata = [[1,2], [3,4]]\ndata_tensor = torch.tensor(data)\n\ndata = [[1,2], [3,4]]\nnp_data = np.array(data)\ndata_tensor = torch.tensor(np_data)\n\ntorch.zeros(5)\ntorch.ones(2, 2)\ntorch.rand(3, 3, 3)\n\nzero_tensor = torch.zeros(3, 3)\nones_like_zeros = torch.ones_like(zero_tensor)\n\n# numpy like indexing\nzero_tensor[0] # return the zero'th row\nones_like_zeros[:, 0] # return the column\n\n# copy of a tensor\nx = ones_like_zeros.detach()\n\nx[:, 0] * 5\n\n# matrix multiplication\nrand1 = torch.rand(5)\nrand2 = torch.rand(5)\ntorch.matmul(rand1, rand2)\n</code></pre>"},{"location":"instances/","title":"Instances","text":"<ul> <li>ml.t3.medium (till assignment 3)</li> <li>ml.g4dn.xLarge (used for machine learning)</li> </ul> <pre><code>tar cvzfh &lt;zip_name.tar.gz&gt; &lt;file_path&gt;\n</code></pre>"},{"location":"intro-deep-learning/","title":"Intro deep learning","text":""},{"location":"intro-ml/","title":"Introduction To Machine Learning","text":""},{"location":"intro-ml/#launcing-sagemaker","title":"Launcing Sagemaker","text":"<p>Amazon SageMaker &gt; Domains &gt;Domain: QuickSetupDomain-20240414T002374 &gt; space management &gt;  &gt; launch studio <p></p>"},{"location":"intro-ml/#delete-apps-to-save-costs","title":"Delete Apps to Save costs","text":"<p>Close all jupyter notebooks</p> <p>Click the space </p> <p>Scroll down and click the app to delete </p> <p>Delete EFS </p>"},{"location":"intro-ml/#definitions","title":"Definitions","text":"<ul> <li>Machine learning is a subfield of artificial intelligence, which is broadly defined as the capability of a machine to imitate intelligent human behavior.</li> <li>Artificial intelligence systems are used to perform complex tasks in a way that is similar to how humans solve problems.</li> </ul>"},{"location":"intro-ml/#how-does-one-tech-a-computer","title":"How does one tech a computer","text":"<ul> <li>The idea was can we create instructions for the computer to create their own set of instructions</li> <li>Eventually, we started to teach computers, that with enough data, and the right set of instructions, they can engineer their own instructions</li> </ul>"},{"location":"intro-ml/#machine-learning-is-everywhere","title":"Machine Learning is Everywhere","text":"<ul> <li>Reccomender systems on youtube, or spotify</li> <li>Medical field in medical imaging in CT and MIR scans</li> </ul>"},{"location":"intro-ml/#useful-links","title":"Useful links","text":"<ul> <li>Elements of statistical learning</li> <li>Introduction to machine learning</li> </ul>"},{"location":"intro-ml/#sagemaker","title":"Sagemaker","text":"<p>AWS machine learning service</p> <ol> <li>Using Sagemaker studio<ul> <li>use it to access datasets from S3 and perform data analysis and functions in AWS tools</li> <li>perform data analysis and feature engineering with Data Wrangler</li> <li>perform data analysis and feature engineering with pandas in sagemaker studio</li> <li>label new data for a dataset using Sagemaker ground truth</li> </ul> </li> <li>Differenciate scenarios where ML can be used<ul> <li>design a domain data, and model outline for a case study</li> <li>build ML life cycle and apply to dataset</li> <li>differenciate between supervised and unsupervised models and apply them to an appropriate dataset</li> <li>differenciate between regression and classification models</li> </ul> </li> <li>Build maching learning models using Sagemaker tools<ul> <li>load dataset, create 3 data set types, identify features/values in SageMaker</li> <li>create new features from data</li> <li>train (fit) a regression and classifcation model using sklearn</li> <li>evaluate a trained model using metrics like MSE, RMSE, r2, accuracy, precision, f1</li> </ul> </li> </ol>"},{"location":"intro-ml/#prerequistes","title":"Prerequistes","text":"<ol> <li>python3 tutorial</li> <li>pandas tutorial</li> <li>jupyterlab</li> </ol>"},{"location":"intro-ml/#business-stakeholders","title":"Business Stakeholders","text":"<ul> <li>Executives - they create the KPIs for their business to succeed. Product managers (PMs) - work with engineers and users of their platform to improve the overall product.</li> <li>Engineers - main stakeholders of the product. They design and build the product that machine learning will integrate with, they are the ones that make the model come to life.</li> <li>Data scientists (DS) - owners of the data that powers machine learning. They often provide insights or initial models that will need to be integrated into the main product.</li> </ul>"},{"location":"intro-ml/#history-of-ml","title":"History of ML","text":"<p>Brief Timeline of Machine Learning</p> <ul> <li>1943 - Warren McCulloch and Walter Pitts created a model for neural networks.</li> <li>1950 - Alan Turing published a paper called \"Computing Machinery and Intelligence\".</li> <li>1959 - Arthur Samuel popularized the phrase machine learning.</li> <li>1965 - Alexey Ivakhnenko and fellow researchers created the first working deep learning networks.</li> <li>1970 - 1980 - ID3 and DART decision tree algorithms were created.</li> <li>1998 - Yann LeCun created the stochastic gradient descent algorithm</li> <li>2011 - Alex Krizhevsky created the AlexNet neural network</li> </ul> <p>Present day - GPUs and TPUs power a larger portion of machine learning. Large option of frameworks and libraries for ML.</p> <p>History of deep learning Google interactive timeline</p>"},{"location":"intro-ml/#when-to-use-ml","title":"When To Use ML","text":"<ol> <li> <p>Define Problem Without a clear definition of what you are trying to solve, it is difficult to build a machine learning model.</p> </li> <li> <p>Measurable Outcome Machine learning is built around learning objectives. Objectives need some way of showing that the model is learning, which is where metrics come into play.</p> </li> <li> <p>Not Simple Solution Simple solutions can often be built using traditional engineering. Machine learning's performance really proves itself when used on complex problems that individuals find difficult to complete.</p> </li> <li> <p>Feasibility If aspects of the machine learning problem are completely impossible, there is no sense in spending time and research for a solution. Working with business stakeholders will assist in proving the reality of a successful outcome.</p> </li> </ol>"},{"location":"intro-ml/#tools-and-environment","title":"Tools and Environment","text":"<ol> <li>excersize and template files</li> <li>project template</li> </ol>"},{"location":"intro-ml/#introduction-to-sagemaker","title":"Introduction to SageMaker","text":"<p>Sagemaker AWS docs</p> <p></p> Sagemaker service Description Sagemaker studio cloud based IDE focused on jupyterlab, and do the whole ML lifecycle, and share and collaborate the cloud Data wrangler perform EDA, feature engineering, and get insights in the IDE Ground truth provides the infastructure to complete annotating data end to end Feature store Feature Store manages all of your features, providing a centralized location to store, update, share, and obtain features. Training pipeline/Endpoint EC2 instance (), S3 (object store), lambda (serverless computing, small bits of code that you can glue together)"},{"location":"intro-ml/#dataframes","title":"Dataframes","text":"<ul> <li>DataFrames are a container for your data</li> <li>Rows are individual events</li> <li>Columns are features and target values</li> <li>The index is the row's unique ID, making it easier to find a row individually</li> </ul> <pre><code>## Creating a simple DataFrame from a dictionary of values\nimport pandas as pd\n\ndf = pd.DataFrame(\n  {\n    'a': [1, 2, 3, 4, 5],\n    'b': ['a', 'b', 'c', 'd', 'f'],\n    'c': [5, 4, 3, 2, 1],\n  }\n)\n</code></pre> <p><code>df.describe()</code> provides summary statistics For numerical values, it provides data for each feature:</p> <p>count - number of rows mean - average value std - standard deviation min - minimum value 25/50/75% - percentile values max - maximum value</p> <pre><code>print(df.describe())\n\n              a         c\ncount  5.000000  5.000000\nmean   3.000000  3.000000\nstd    1.581139  1.581139\nmin    1.000000  1.000000\n25%    2.000000  2.000000\n50%    3.000000  3.000000\n75%    4.000000  4.000000\nmax    5.000000  5.000000\n</code></pre> <p><code>df.hist()</code> plots histograms - Plot the distribution of values - Help identify outliers or unexpected values - Normal, Uniform, chi-square, F are examples of different distributions</p> <p><code>df.corr()</code> calculates a correlation matrix - Correlation is the relationship between two variables - Values from correlation range from -1.0 to 1.0 - -1.0 is a strong negative relationship - 1.0 is a strong positive relationship - Diagonal matrix values always 1.0 - Strong positive or negative relationships add little to ML models</p> <pre><code>print(df.corr())\n\"\"\"\n     a    c\na  1.0 -1.0\nc -1.0  1.0\n\"\"\"\n</code></pre> <p>Information Gain - one piece of information would be to check outside if its raining, and the other is checking your weather app using both would not be useful</p>"},{"location":"project1/","title":"Project1","text":"<ul> <li>My git repo</li> <li>Github project template</li> <li>Kaggle bike sharing demand</li> </ul> <pre><code>!pip install -U pip\n!pip install -U setuptools wheel\n!pip install torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cpu\n!apt-get update; apt-get install -y graphviz graphviz-dev\n!pip install autogluon kaggle pygraphviz dask[dataframe]\n</code></pre> <pre><code># you need a kaggle.json file\nkaggle competitions download -c bike-sharing-demand\n</code></pre> <p>project 1 code snippet</p> <pre><code>\nremove_columns = [\"casual\", \"registered\"]\ntrain_ex_cas_reg = train.drop(columns=remove_columns)\n\npredictor = TabularPredictor(label=\"count\", eval_metric=\"root_mean_squared_error\").fit(\n    train_data=train_ex_cas_reg,\n    time_limit=600,\n    presets=\"best_quality\"\n)\n</code></pre> <p>scoring function </p> <pre><code>from autogluon.core.metrics import make_scorer\nimport sklearn\n\ndef rmsle_func(y_true, y_pred, **kwargs):    \n    return sklearn.metrics.root_mean_squared_log_error(y_true, y_pred, **kwargs)\n\nroot_mean_squared_log_error = make_score(\"root_mean_squared_log_error\", rmsle_func, optimum=0, greater_is_better=False)\n</code></pre>"}]}